{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, cv2, re, random\nimport numpy as np\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras import layers, models, optimizers\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nimport zipfile","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_ZIP = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'\nzip_ref = zipfile.ZipFile(TEST_ZIP, 'r')\nzip_ref.extractall('test_all')\nzip_ref.close()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_ZIP = '../input/dogs-vs-cats-redux-kernels-edition/train.zip'\nzip_ref = zipfile.ZipFile(TRAIN_ZIP, 'r')\nzip_ref.extractall('training')\nzip_ref.close()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width = 150\nimg_height = 150\nTRAIN_DIR = '/kaggle/working/training/train/'\nTEST_DIR = '/kaggle/working/test_all/test/'\n\ntrain_images_dogs_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntest_images_dogs_cats = [TEST_DIR+i for i in os.listdir(TEST_DIR)]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def atoi(text):\n    return int(text) if text.isdigit() else text\n\ndef natural_keys(text):\n    return [ atoi(c) for c in re.split('(\\d+)', text) ]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_dogs_cats.sort(key=natural_keys)\ntrain_images_dogs_cats = train_images_dogs_cats[0:1300] + train_images_dogs_cats[12500:13800] \n\ntest_images_dogs_cats.sort(key=natural_keys)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(list_of_images):\n    \"\"\"\n    Returns two arrays: \n        x is an array of resized images\n        y is an array of labels\n    \"\"\"\n    x = [] # images as arrays\n    y = [] # labels\n    \n    for image in list_of_images:\n        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n    \n    for i in list_of_images:\n        if 'dog' in i:\n            y.append(1)\n        elif 'cat' in i:\n            y.append(0)\n        #else:\n            #print('neither cat nor dog name present in images')\n    return x, y           ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, Y = prepare_data(train_images_dogs_cats)\nprint(K.image_data_format())","execution_count":9,"outputs":[{"output_type":"stream","text":"channels_last\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = len(X_train)\nnb_validation_samples = len(X_val)\nbatch_size = 16","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(layers.Conv2D(32, (3, 3)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1))\nmodel.add(layers.Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\nmodel.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 148, 148, 32)      896       \n_________________________________________________________________\nactivation (Activation)      (None, 148, 148, 32)      0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 72, 72, 32)        9248      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 72, 72, 32)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 34, 34, 64)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 18496)             0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                1183808   \n_________________________________________________________________\nactivation_3 (Activation)    (None, 64)                0         \n_________________________________________________________________\ndropout (Dropout)            (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 65        \n_________________________________________________________________\nactivation_4 (Activation)    (None, 1)                 0         \n=================================================================\nTotal params: 1,212,513\nTrainable params: 1,212,513\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size)\nvalidation_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    train_generator, \n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=30,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_samples // batch_size\n)","execution_count":15,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n130/130 [==============================] - 15s 113ms/step - loss: 0.7031 - accuracy: 0.5337 - val_loss: 0.6650 - val_accuracy: 0.6035\nEpoch 2/30\n130/130 [==============================] - 15s 118ms/step - loss: 0.6641 - accuracy: 0.6072 - val_loss: 0.6342 - val_accuracy: 0.6406\nEpoch 3/30\n130/130 [==============================] - 15s 114ms/step - loss: 0.6434 - accuracy: 0.6385 - val_loss: 0.6298 - val_accuracy: 0.6504\nEpoch 4/30\n130/130 [==============================] - 14s 111ms/step - loss: 0.6138 - accuracy: 0.6832 - val_loss: 0.5905 - val_accuracy: 0.7129\nEpoch 5/30\n130/130 [==============================] - 14s 111ms/step - loss: 0.6114 - accuracy: 0.6894 - val_loss: 0.6442 - val_accuracy: 0.6250\nEpoch 6/30\n130/130 [==============================] - 16s 119ms/step - loss: 0.5762 - accuracy: 0.6990 - val_loss: 0.6061 - val_accuracy: 0.6855\nEpoch 7/30\n130/130 [==============================] - 15s 112ms/step - loss: 0.5780 - accuracy: 0.6995 - val_loss: 0.6115 - val_accuracy: 0.6934\nEpoch 8/30\n130/130 [==============================] - 15s 113ms/step - loss: 0.5659 - accuracy: 0.7111 - val_loss: 0.6156 - val_accuracy: 0.6641\nEpoch 9/30\n130/130 [==============================] - 15s 115ms/step - loss: 0.5510 - accuracy: 0.7332 - val_loss: 0.5339 - val_accuracy: 0.7383\nEpoch 10/30\n130/130 [==============================] - 15s 117ms/step - loss: 0.5445 - accuracy: 0.7409 - val_loss: 0.5642 - val_accuracy: 0.7207\nEpoch 11/30\n130/130 [==============================] - 15s 113ms/step - loss: 0.5175 - accuracy: 0.7442 - val_loss: 0.8889 - val_accuracy: 0.6055\nEpoch 12/30\n130/130 [==============================] - 14s 109ms/step - loss: 0.5099 - accuracy: 0.7524 - val_loss: 0.5721 - val_accuracy: 0.7188\nEpoch 13/30\n130/130 [==============================] - 14s 108ms/step - loss: 0.5417 - accuracy: 0.7654 - val_loss: 0.5339 - val_accuracy: 0.7383\nEpoch 14/30\n130/130 [==============================] - 16s 124ms/step - loss: 0.4950 - accuracy: 0.7793 - val_loss: 0.5654 - val_accuracy: 0.7246\nEpoch 15/30\n130/130 [==============================] - 14s 110ms/step - loss: 0.5015 - accuracy: 0.7760 - val_loss: 0.5174 - val_accuracy: 0.7500\nEpoch 16/30\n130/130 [==============================] - 15s 113ms/step - loss: 0.4711 - accuracy: 0.7817 - val_loss: 0.6762 - val_accuracy: 0.7070\nEpoch 17/30\n130/130 [==============================] - 14s 111ms/step - loss: 0.4543 - accuracy: 0.7986 - val_loss: 0.5573 - val_accuracy: 0.7090\nEpoch 18/30\n130/130 [==============================] - 15s 119ms/step - loss: 0.4782 - accuracy: 0.7798 - val_loss: 0.4963 - val_accuracy: 0.7656\nEpoch 19/30\n130/130 [==============================] - 14s 109ms/step - loss: 0.4637 - accuracy: 0.7957 - val_loss: 0.6195 - val_accuracy: 0.7344\nEpoch 20/30\n130/130 [==============================] - 15s 114ms/step - loss: 0.4710 - accuracy: 0.7913 - val_loss: 0.5142 - val_accuracy: 0.7441\nEpoch 21/30\n130/130 [==============================] - 14s 110ms/step - loss: 0.4523 - accuracy: 0.7976 - val_loss: 0.5017 - val_accuracy: 0.7578\nEpoch 22/30\n130/130 [==============================] - 15s 119ms/step - loss: 0.4512 - accuracy: 0.7952 - val_loss: 0.6432 - val_accuracy: 0.6973\nEpoch 23/30\n130/130 [==============================] - 15s 112ms/step - loss: 0.4439 - accuracy: 0.7990 - val_loss: 0.5376 - val_accuracy: 0.7578\nEpoch 24/30\n130/130 [==============================] - 15s 113ms/step - loss: 0.4283 - accuracy: 0.8168 - val_loss: 0.5126 - val_accuracy: 0.7480\nEpoch 25/30\n130/130 [==============================] - 14s 108ms/step - loss: 0.4377 - accuracy: 0.8082 - val_loss: 0.4948 - val_accuracy: 0.7695\nEpoch 26/30\n130/130 [==============================] - 16s 121ms/step - loss: 0.4254 - accuracy: 0.8231 - val_loss: 0.5132 - val_accuracy: 0.7383\nEpoch 27/30\n130/130 [==============================] - 14s 109ms/step - loss: 0.4200 - accuracy: 0.8245 - val_loss: 0.5213 - val_accuracy: 0.7715\nEpoch 28/30\n130/130 [==============================] - 14s 109ms/step - loss: 0.4316 - accuracy: 0.8188 - val_loss: 0.4732 - val_accuracy: 0.7773\nEpoch 29/30\n130/130 [==============================] - 15s 112ms/step - loss: 0.4099 - accuracy: 0.8269 - val_loss: 0.4856 - val_accuracy: 0.7637\nEpoch 30/30\n130/130 [==============================] - 15s 117ms/step - loss: 0.4238 - accuracy: 0.8298 - val_loss: 0.5366 - val_accuracy: 0.7695\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('model_wieghts.h5')\nmodel.save('model_keras.h5')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, Y_test = prepare_data(test_images_dogs_cats)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1. / 255)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = val_datagen.flow(np.array(X_test), batch_size=batch_size)\nprediction_probabilities = model.predict_generator(test_generator, verbose=1)","execution_count":19,"outputs":[{"output_type":"stream","text":"782/782 [==============================] - 68s 87ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = range(1, len(test_images_dogs_cats) + 1)\nsolution = pd.DataFrame({\"id\": counter, \"label\":list(prediction_probabilities)})\ncols = ['label']\n\nfor col in cols:\n    solution[col] = solution[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)\n\nsolution.to_csv(\"dogsVScats.csv\", index = False)","execution_count":20,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}